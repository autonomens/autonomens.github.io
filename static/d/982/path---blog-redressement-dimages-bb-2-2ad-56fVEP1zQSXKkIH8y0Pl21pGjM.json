{"data":{"markdownRemark":{"id":"b704c9a3-1f74-5e73-8159-fa5d54c34c5c","html":"<p>Dans le cadre du développement d'une application, nous avons du mettre un place un module de comparaison d'images deux à deux. Le principe du comparateur est simple et efficace : un pointeur simultané permet de se situer sur les deux images à la fois, accompagné d'un zoom (comme dans l'application <a href=\"https://makina-corpus.com/realisations/conseil-general-de-loire-atlantique\">VuDuCiel</a>). Pourtant, quelque chose nous dérange, du moins ne nous satisfait pas dans ce module. Les images ne sont en effet pas cadrées de la même manière entre deux prises de vue et le pointeur montre certes le même point en termes de position sur les images mais pas géographiquement parlant.</p>\n<p>Pour contourner ce problème, nous nous sommes donc penchés sur le redressement d'images. Il s'agit de transformer une image - de la redresser - pour qu'elle soit superposable à une celle qui lui sert de modèle. Cela peut se faire simplement en détectant dans les deux images des points saillants qui vont servir de repères pour la transformation.<br>\nLe traitement est expliqué ci-dessous mais peut également être suivi via un notebook Jupyter disponible sur notre <a href=\"https://github.com/makinacorpus/tutorials/tree/master/images_adjustment\">GitHub</a>. Nous utilisons Python mais plus particulièrement la bibliothèque <a href=\"https://pypi.org/project/opencv-python/\">OpenCV</a> pour arriver à bout du redressement.</p>\n<p><img src=\"https://makina-corpus.com/blog/metier/2019/redressement-dimage-images-de-depart-1\" alt=\"initial_images\">\n<em>Voici les images dans le module de comparaison : le curseur ne pointe pas sur les mêmes éléments entre les deux photographies. Nous allons utiliser image de gauche comme référence et l'image de droite va être redressée.</em></p>\n<h2>Première étape : les points saillants</h2>\n<p>Les points saillants sont définis par des structures de l'image qui peuvent se distinguer facilement de leur environnement. Par exemple, des changements nets de contraste ou de lumière sont souvent utilisés pour les identifier. Des points saillants typiques seraient des bordures ou des coins, caractérisés par une importante différence au niveau du contraste. À chaque point saillant détecté est associé un descripteur qui le caractérise de façon unique. Ainsi, un point saillant est censé avoir le même descripteur lorsqu'il est détecté sur une autre image, quelque soit la position et l'orientation de l'appareil photo. Il existe d'ailleurs plusieurs algorithmes de détection de points saillants qui ont sont plus ou moins sensibles aux changements de cadrage entre deux prises de vue. L'un des robustes et des plus réputés est l'algorithme <a href=\"https://robo.fish/wiki/images/5/58/Image_Features_From_Scale_Invariant_Keypoints_Lowe_2004.pdf\">SIFT</a> : il est non seulement insensible aux changements de position et d'orientation mais aussi d'échelle.  </p>\n<p>Dans le code ci-dessous, <code>im_ref</code> et <code>im</code> font référence à nos deux images de travail. <code>im_ref</code> est notre image d'origine et nous souhaitons redresser <code>im</code> pour qu'elle corresponde à <code>im_ref</code>.</p>\n<pre><code>import cv2\n\n# Initiate SIFT detector\nsift = cv2.xfeatures2d.SIFT_create()\n\n# Find keypoints and compute descriptors with SIFT\nkp_ref, des_ref = sift.detectAndCompute(im_ref, None)\nkp, des = sift.detectAndCompute(im, None)\n</code></pre>\n<p>Les variables <code>kpX</code> et <code>desX</code> correspondent respectivement aux points saillants sur l'image X (kp = <em>keypoint</em>) et à leur descripteur associé (des = <em>descriptor</em>).</p>\n<p><img src=\"https://makina-corpus.com/blog/metier/2019/redressement-dimage-points-cles\" alt=\"detected_keypoints\">\n<em>Points saillants détectés</em></p>\n<h2>Association des points saillants</h2>\n<p>Maintenant que les points saillants ont été détectés sur les deux images, nous souhaitons créer les paires de points qui se ressemblent assez, d'après leur descripteur, pour considérer que ce sont les mêmes dans la réalité.<br>\nIl existe plusieurs algorithmes pouvant réaliser cette tâche, ce sont des <em>Matchers</em>. La fonction d'association est généralement longue à s'exécuter car pour chacun des point saillants de la première image, tous les points saillants de la seconde image sont testés afin de trouver la meilleure association. Un tri a ensuite lieu pour ne garder que les associations les plus fiables.\nOpenCV propose, entres autres, <em>Brute-Force matcher</em>, un algorithme assez simple qui calcule la distance entre les descripteurs des points saillants. Le point saillant le plus proche est considéré comme étant la meilleure association.</p>\n<pre><code># Create BFMatcher object with default parameters\nbf = cv2.BFMatcher()\n\n# Match descriptors\nmatches = bf.knnMatch(des, des_ref, k=2)\n\n# Store all the good matches as per Lowe's ratio test\n# Can play with variable factor:\n# if factor = 1, all matches are taken into account,  if factor = 0 none of them are considered\ngood_matches = []\nfactor = 0.6\nfor m, n in matches:\n    if m.distance &#x3C; factor * n.distance:\n        good_matches.append(m)\n\n# Retrieve your keypoints in `good_matches`\ngood_kp = np.array([kp[match.queryIdx].pt for match in good_matches])\ngood_kp_ref = np.array([kp_ref[match.trainIdx].pt for match in good_matches])\n</code></pre>\n<p><img src=\"https://makina-corpus.com/blog/metier/2019/redressement-dimage-matching\" alt=\"matching_keypoints\">\n<em>Association des points saillants entre deux images</em></p>\n<h2>Finalement, le redressement</h2>\n<p>Les paires de points saillants établies à l'étape précédente nous permettent maintenant de déduire la transformation qu'il existe entre les deux images. On appelle cette transformation homographie (ou par son nom barbare : application projective bijective). Concrètement, cela signifie que tout élément dans notre image non transformée apparaîtra, de façon unique, dans l'image transformée. De plus, les éléments conserveront leur typologie : un point reste un point, un ligne reste une ligne et un polygone reste un polygone ! Ainsi, les objets de l'image ne disparaissent pas (ou ne sont pas dédoublés) et gardent leur nature d'origine lors de la transformation.<br>\nAppliquons la transformation homographique à l'image qui doit être redressée :</p>\n<pre><code># Find transformation\nm, mask = cv2.findHomography(good_kp, good_kp_ref, cv2.RANSAC, 5.0)\n\n# Apply transformation\nim_adjusted = cv2.warpPerspective(im, m, (w, h))\n</code></pre>\n<p>Dans le code ci-dessus, <code>w</code> et <code>h</code> représentent la largeur (<em>width</em>) et la hauteur (<em>height</em>) de sortie de l'image transformée.\nLa première étape est de trouver, à partir des points saillants associés précédemment, la matrice définissant l'homographie. L'algorithme RANSAC (Random Sample Consensus) est ici appelé pour supprimer les éventuelles associations aberrantes. Le paramètre égal à <code>5.0</code> correspond à la tolérance de l'algorithme RANSAC pour détecter ces associations. Nous obtenons alors la matrice de transformation <code>m</code>.  Celle-ci nous permet alors de passer à la deuxième étape, l'application de l'homographie sur l'image !</p>\n<p><img src=\"https://makina-corpus.com/blog/metier/2019/redressement-dimage-overlay\" alt=\"redressement\">\n<em>Superposition des images avant redressement (à gauche) et après redressement (à droite)</em></p>\n<h2>Conclusion</h2>\n<p>Ce traitement nous a permis de redresser notre image par rapport à une image de référence afin d'avoir un cadrage similaire. Voici un aperçu du module de comparaison avec l'image redressée, le curseur pointe bien sur le même élément dans les deux images :</p>\n<p><img src=\"https://makina-corpus.com/blog/metier/2019/redressement-dimage-comparaison-finale\" alt=\"comparaison_finale\">\n<em>Module de comparaison avec l'image redressée à droite.</em></p>\n<p>Le redressement d'images nous ouvre alors la porte vers de nombreuses applications : comparaison superposée, détection de changements automatique... Si l'une d'entre elles vous inspire ou si vous souhaitez de l'aide pour analyser et valoriser vos images, n'hésitez pas à <a href=\"mailto:contact@makina-corpus.com\" class=\"btn\">nous contacter</a> !</p>","frontmatter":{"date":"March 03, 2017","title":"Utilisation de la vision par ordinateur pour redresser des images","description":"Dans un module de comparaison d'images, lorsque deux photographies ne sont pas cadrées de la même manière, non-superposable, c'est frustrant. On vous propose ici d'y remédier avec du redressement d'images par homographie.","tags":["image","traitement"]}}},"pageContext":{"id":"b704c9a3-1f74-5e73-8159-fa5d54c34c5c"}}